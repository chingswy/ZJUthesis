

\newcommand{\qczb}{齐次坐标}
\newpage
\section{人体三维姿态估计问题的研究}
\subsection{问题描述}
三维人体姿态估计问题，即是说给定输入的人体图片或视频序列，从中得到人体的三维关节点的位置。从上一节中我们已经得到了人体的二维关节点位置，因此对于这一部分我们需要得到相应的人体三维姿态的估计。但是在只有单个视角的情况下，三维估计具有尺度和深度的不确定性。在只有一个相机的情况下，通常使用各种先验信息来减少这种不确定性，在我们的实验场景下，我们可以利用多个相机的空间信息，来优化求解人体的三维关节点的坐标。

\subsection{相机标定}
\subsubsection{相机模型}
% https://www.cnblogs.com/wangguchangqing/p/8126333.html#autoid-0-4-0
相机进行图像拍摄的过程涉及到了多个坐标系的转换，即先从世界坐标系进行刚性变换，转换到相机坐标系，从相机坐标系进行投影变换，转换到图像坐标系，最后根据相机参数，转换到像素坐标系上，像素坐标系就是我们一般意义上所指的图像。几个坐标系的简介如下：
\begin{description}
    \item[世界坐标系：] 是用来描述客观世界的坐标系，描述的是相机三维空间中的其他物体的值，一般用\((x_w, y_w, z_w)\)表示世界坐标系中的值。
    \item[相机坐标系：] 相机坐标系是建立在相机上的坐标系，该坐标系的原点是相机的光心，坐标系的\(x\)轴和\(y\)轴分别平行于图像坐标系的\(x\)轴和\(y\)轴，坐标系的\(z\)轴为相机的光轴。一般用\((x_c,y_c,z_c)\)表示其坐标值。
    \item[图像坐标系：] 图像坐标系的坐标原点是图像平面的中心，图像坐标系是用实际物理单位表示像素在图像中的位置，通常用\((x,y)\)表示其坐标值。
    \item[像素坐标系：] 像素坐标系的原点是图像平面的左上角顶点，通常用\((u,v)\) 表示其坐标值。像素坐标系即是图像在计算机内存储的坐标系，计算机保存时每张图一般用\(M\times N\)的矩阵来表示，其中的每一个元素叫做图像的像素，每一个元素的数值代表图像的像素值。
\end{description}

对于空间中一点，其在世界坐标系中的坐标记为\(P_w\)，其在相机坐标系中的坐标记为\(P_c\)，那么我们可以使用刚性变换来描述其转换过程，即通过一个旋转矩阵\(R\)，与一个平移向量\(T\)，将\(P_w\)变换为\(P_c\)，即
\begin{equation}
    P_c = RP_w + t
\end{equation}
其中，\(R\)是一个\(3\times 3\)的旋转矩阵，\(T \in \mathbb{R}^{3}\) 表示平移向量。上式在运算的过程中需要进行加法，因此通常在进行计算时，为了简化表示，使用\qczb 来表示点在空间中的位置，从世界坐标系变换到相机坐标系时，其转换方式为
\begin{equation}
    \left[\begin{array}{c}X_c\\Y_c\\Z_c\end{array}\right] = \left[\begin{array}{ccc}R_{11}&R_{12}&R_{13}\\R_{21}&R_{22}&R_{23}\\R_{31}&R_{32}&R_{33}\end{array}\right]\left[\begin{array}{c}X_w\\Y_w\\Z_w\end{array}\right] + \left[\begin{array}{c}t_1\\t_2\\t_3\end{array}\right]
\end{equation}
写成\qczb 的形式为
\begin{equation}
    \left[\begin{array}{c}X_c\\Y_c\\Z_c\\1 \end{array}\right] =
    \left[\begin{array}{cccc}R_{11}&R_{12}&R_{13}&t_1\\R_{21}&R_{22}&R_{23}&t_2\\R_{31}&R_{32}&R_{33}&t_3\\0&0&0&1\end{array}\right]
    \left[\begin{array}{c}X_w\\Y_w\\Z_w\\1\end{array}\right]
\end{equation}
该转换矩阵就记为相机的外部参数\(T\):
\begin{equation}
    T = \left[\begin{array}{cc}R&T\\0^T&1\end{array}\right]
\end{equation}

从相机坐标系变换到图像坐标系是一个从三维空间的点变换到二维空间中的点的过程，这个过程也叫射影变换。利用相似三角形原理，可以得到
\begin{equation}
    \left\{
    \begin{array}{l}
        x = f\frac{X}{Z} \\
        y = f\frac{Y}{Z} \\
        z = f
    \end{array}\right.
\end{equation}
由于该计算过程中对\(z\)是非线性的，因此引入一个中间变量，先使用矩阵乘法进行计算
\begin{equation}
    \left[\begin{array}{c}\hat{x}\\\hat{y}\\\hat{z}\end{array}\right] =
    \left[\begin{array}{cccc}f&0&0&0\\0&f&0&0\\0&0&1&0\end{array}\right]
    \left[\begin{array}{c}X\\Y\\Z\\1\end{array}\right]
\end{equation}
再通过将该坐标值除以其\(z\)的值，即可得到图像坐标系的值
\begin{equation}
    \left\{\begin{array}{l}x=\dfrac{\hat{x}}{\hat{z}} \\y=\dfrac{\hat{y}}{\hat{z}}
        \\z\ne0\end{array}\right.
\end{equation}

最后需要从图像坐标系转换到像素坐标系，该转换过程是一个线性变换，即是说图像坐标系中的点的坐标与像素坐标系中的点相差了一个缩放和平移。那么其计算公式就可以写为
\begin{equation}
    \begin{array}{c}
        u = \alpha\cdot x+ c_x \\
        v = \beta \cdot y + c_y
    \end{array}
\end{equation}
将上面的公式代入，即可以得到
\begin{equation}
    \left\{\begin{array}{c}
        u = \alpha\cdot f\frac{X}{Z}+ c_x = f_x\frac{X}{Z}+ c_x \\
        v = \beta \cdot f\frac{Y}{Z} + c_y = f_y\frac{Y}{Z} + c_y
    \end{array}\right.
\end{equation}
其中\(f_x = \alpha \cdot f,f_y = \beta \cdot f\)，同样将上式改写成\qczb 的形式，即可以得到
\begin{equation}
    \left[\begin{array}{c}\mu\\\nu\\1\end{array}\right] = \frac{1}{Z}\left[
        \begin{array}{ccc}f_x&0&c_x\\0&f_y&c_y\\0&0&1\end{array}\right]\left[\begin{array}{c}X\\Y\\Z\end{array}\right]
\end{equation}
通过该式子，即可以得到相机的内部参数矩阵\(K\)，
\begin{equation}
    K=\left[
        \begin{array}{ccc}f_x&0&c_x\\0&f_y&c_y\\0&0&1\end{array}\right]
\end{equation}
从相机内部参数的表达式中可以看出，其中的未知数与相机的实际物理参数有关，那么整个相机的投影过程就可以写为：
\begin{equation}
    Z\left[\begin{array}{c}u\\v\\1\end{array}\right] =
    \left[\begin{array}{ccc}\frac{1}{dx}&0&c_x\\0&\frac{1}{dy}&c_y\\0&0&1\end{array}\right]
    \left[\begin{array}{cccc}f&0&0&0\\0&f&0&0\\0&0&1&0\end{array}\right]
    \left[\begin{array}{cc}R&t\\0^T&1\end{array}\right]
    \left[\begin{array}{c}X_w\\Y_w\\Z_w\\1\end{array}\right]
\end{equation}
因此在使用相机前，需要先对相机的内部参数进行求解，求解该内部参数的过程即为标定。在标定的过程中即需要求解相机的内部参数与外部参数。接下来将介绍LightStage系统的标定过程。

\subsubsection{标定原理}
% https://www.cnblogs.com/wangguchangqing/p/8335131.html

目前主流的相机标定方法是微软研究院的张正友教授与1998年提出的一种利用单个棋盘格平面进行相机标定的方法，该方法介于传统标定法和自标定法之间，标定效果较好，并且计算复杂度低。同时不需要高精度的标定物，便于操作。因此我们使用该方法进行相机的标定。



% \comment{这里写相机标定的内容}
假设三维世界坐标系中的点的\qczb 为\(X = [x,y,z,1]^T\)，其在二维相机平面上的\qczb 为\(m = [u,v,1]^T\)。那么由相机模型的定义我们可以知道：

\begin{equation}
    Z \bm{m} = K(R\bm{X} + T)
\end{equation}
在进行标定时，假设棋盘格所在平面为世界坐标系中的\(Z=0\)的平面，那么则有
\begin{equation}
    Z\left[ \begin{array}{c} u \\ v \\ 1 \end{array} \right] = K\left[
        \begin{array}{cccc} r_1 & r_2 & r_3 & t\end{array}
        \right]
    \left[
        \begin{array}{c}x \\y \\0 \\1\end{array}
        \right]=K
    \left[
        \begin{array}{cccc} r_1 & r_2 & T\end{array}
        \right]
    \left[
        \begin{array}{c}x \\y \\1\end{array}
        \right]
\end{equation}
其中\(r_1,r_2,r_3\)分别代表旋转矩阵\(R\)的列向量，令
\begin{equation}
    H=[h_1\ h_2\ h3] = \lambda K[r_1\ r_2\ t]
\end{equation}
该矩阵即为棋盘格平面到像素平面的变换矩阵，记为单应性矩阵。\(H\)是一个齐次矩阵，因此有8个未知数，至少需要8个方程来进行求解。由上式可得：
\begin{align}
    \lambda & = \frac{1}{Z}                 \\
    r_1     & = \frac{1}{\lambda} K^{-1}h_1 \\
    r_2     & = \frac{1}{\lambda} K^{-1}h_2
\end{align}

由于\(R\)是旋转矩阵，\(r_1, r_2\)分别是旋转矩阵的两列，因此这两个向量正交，同时这两个向量都是单位向量，那么则有
\begin{align}
    r_1^Tr_2        & =0 \\
    ||r_1||=||r_2|| & =1
\end{align}
代入可得：
\begin{align}
    h_1^TK^{-T}K^{-1}h_2 & =0                     \\
    h_1^TK^{-T}K^{-1}h_1 & = h_2^TK^{-T}K^{-1}h_2
\end{align}
也即是说每个单应性矩阵能够提供两个方程，而内部参数矩阵\(K\)包含了5个参数，因此要进行求解需要至少三个单应性矩阵\(H\)。其中记\(B = A^{-T}A^{-1}\)，显然\(B\)为实对称矩阵，将其展开即得
\begin{align}
    B & =K^{-T}K^{-1}=
    \left[
        \begin{array}{ccc}
            B_{11} & B_{12} & B_{13} \\
            B_{21} & B_{22} & B_{23} \\
            B_{31} & B_{32} & B_{33}
        \end{array}
        \right]        \\ &=
    \left[
        \begin{array}{ccc}
            \dfrac{1}{\alpha^2}                       & -\dfrac{\gamma}{\alpha^2\beta}                                            & \dfrac{v_0\gamma-u_0\beta}{\alpha^2\beta}                                 \\
            -\dfrac{\gamma}{\alpha^2\beta}            & \dfrac{\gamma^2}{\alpha^2\beta^2}+\dfrac{1}{\beta^2}                      & -\dfrac{\gamma(v_0\gamma-u_0\beta)}{\alpha^2\beta^2}-\dfrac{v_0}{\beta^2} \\
            \dfrac{v_0\gamma-u_0\beta}{\alpha^2\beta} & -\dfrac{\gamma(v_0\gamma-u_0\beta)}{\alpha^2\beta^2}-\dfrac{v_0}{\beta^2} & \dfrac{(v_0\gamma-u_0\beta)^2}{\alpha^2\beta^2}+\dfrac{v_0}{\beta^2}+1
        \end{array}
        \right]
\end{align}
由于\(B\)为对称矩阵，因此将\(B\)的有效元素写成向量\(b\)，即
\begin{equation}
    b=\left[ \begin{array}{cccccc} B_{11} & B_{12} & B_{22} & B_{13} & B_{23} & B_{33} \end{array} \right]^T
\end{equation}
那么之前的式子可以利用向量\(b\)来进行化简：
即式子
\begin{equation}
    h_i^TBh_j = v^T_{ij}b
\end{equation}
其中的系数矩阵为
\begin{equation}
    v_{ij}=\left[ \begin{array}{cccccc} h_{i1}h_{j1} & h_{i1}h_{j2}+h_{i2}h_{j1} & h_{i2}h_{j2} & h_{i3}h_{j1}+h_{i1}h_{j3} & h_{i3}h_{j2}+h_{i2}h_{j3} & h_{i3}h_{j3} \end{array} \right]^T
\end{equation}
那么之前关于矩阵\(B\)的两个约束条件就可以写成
\begin{equation}
    \left[ \begin{array}{c} v^T_{12} \\ (v_{11}-v_{22})^T \end{array} \right]b=0
\end{equation}
因此，基于上式，通过至少三张包含棋盘格的图像，就可以解得矩阵\(B\)，再使用Cholesky分解法，就可以得到相机的内部参数矩阵\(K\)。
\begin{figure}[htbp]
    \centering
    \subfigure[同一相机多个姿势的标定板]{
        \begin{minipage}[t]{0.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figure/calibrate/single_c} %
        \end{minipage}% 
    }% 
    \subfigure[标定板角点检测结果]{
        \begin{minipage}[t]{0.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figure/calibrate/single_cp} %
        \end{minipage}% 
    }%
    \caption{单个相机的标定示意\label{fig:calsingle}}
\end{figure}

当所有相机的内部参数确定之后，就需要确定所有相机的外部参数。最开始采用的方法是，对于相邻的两个相机，我们采集一组在这两个相机视角下都可见的棋盘格照片，标定相邻两个相机的相对变换矩阵，接着依次将所有的相机都标定，但是这样标定的过程中，相邻两个相机的标定误差会不断传递，因此整体的标定效果较差。因此，为了避免累积误差的出现，我们直接对所有相机的外参同时进行计算。
\begin{figure}[htbp]
    \centering
    \subfigure[相机视角1]{
        \begin{minipage}[t]{0.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figure/calibrate/all1} %
        \end{minipage}% 
    }% 
    \subfigure[相机视角2]{
        \begin{minipage}[t]{0.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figure/calibrate/all3} %
        \end{minipage}% 
    }%
    \subfigure[相机视角3]{
        \begin{minipage}[t]{0.45\linewidth}
            \centering
            \includegraphics[width=\linewidth]{figure/calibrate/all4} %
        \end{minipage}% 
    }%
    \caption{所有相机标定示意\label{fig:calall}}
\end{figure}


\unsure{}{这里需要抄一下PnP的原理}
在解出所有相机的内部参数之后，我们需要对所有的相机的外部参数进行求解，即求解相机的相对于世界坐标系的旋转矩阵\(R\)，以及相对于世界坐标系的平移\(T\)。这个问题本质上是一个PnP问题，即已知了\(n\)个三维空间点的坐标以及二维投影的位置的时候，如何去估计相机的位姿。

\subsubsection{标定实现}
由于LightStage系统的相机较多，与单个相机的标定方法有所区别，因此我们的标定主要分为以下步骤：
\begin{description}
    \item[棋盘格制作：]一般的简单的相机标定使用的通常是打印在A4纸上的棋盘格，但是我们的使用场景较大，因此A4纸大小的棋盘格太小了，我们制作了一个较大的棋盘格，棋盘格的每一个格子的边长为10cm，我们使用的是有\(10\times 6\)的棋盘格，即其内部会有\(9\times 6\)个网格点。
    \item[标定单个相机：]在这一步中，我们对于每一个相机，录制一段拿着棋盘格的在相机的不同位置，以及棋盘格自身是不同姿态的视频，使用录制的视频进行棋盘格角点检测，进行一次标定操作，得到所有的单个相机的内部参数
    \item[标定所有相机外参：]在这一步中，我们将棋盘格静止放置在系统的中间的位置，保证所有相机都能看到棋盘格，使用所有相机同时录制。得到所有视角下的棋盘格的照片后，对其角点位置进行检测，接着使用解PnP问题求解出所有相机的外部参数。
\end{description}

由于使用棋盘格进行标定是一件很成熟的工作，因此在明白标定过程的原理之后，我们的大部分工作只需要调用可以使用的函数就可以了。我们的标定过程分为两步，第一步使用的是OpenCV的标定函数。我们的代码主要分为以下几步：
\begin{description}
    \item[角点检测：]使用OpenCV的\textrm{findChessboardCorners}函数进行角点检测，该函数的输入是需要寻找角点的图片，该棋盘格的样式，该函数将会返回按顺序存储的棋盘格角点的图片中的坐标，这里的顺序是按照棋盘格的顺序生成的。
    \item[棋盘格三维坐标计算：]在进行相机标定时，我们需要预先计算棋盘格的在空间中的三维坐标，由之前的推导，我们在进行相机标定的时候都是假设棋盘格所在的平面为\(z=0\)平面，因此这一步需要根据棋盘格的实际物理尺寸，依次给棋盘格上的每个点按顺序计算其坐标。
    \item[内参标定：]这一步使用的是OpenCV的\textrm{calibrateCamera}函数，该函数的输入是我们预先计算的棋盘格的在三维空间中的坐标，以及角点检测得到的在图片中的像素坐标，该函数将返回相机的内部参数矩阵，相机的畸变系数，以及对应的每一张图片的外部参数。
    \item[外参计算：]这一步将会读入之前的内部参数的计算结果，同样使用OpenCV的\textrm{findChessboardCorners}函数，对输入的同一时刻的所有相机的图片进行角点检测，通过使用OpenCV的\textrm{solvePnP}函数求解所有相机的外部参数。该函数的输入参数为棋盘格在空间中的三维坐标，棋盘格在图片中的坐标，相机的内部参数。该函数将返回相机的外部参数\(r, t\)。
\end{description}

% \unsure{}{标定板参数介绍，内参标定误差分析，外参标定误差。外参标定的结果可视化}
\unsure{}{这里差一个所有相机的标定结果的可视化分析}
\subsubsection{误差分析}
为了检测相机标定的质量，我们需要对该过程进行误差分析，由于对于单个相机的标定与对所有相机的标定过程是分开的，因此我们分别对这两部分进行误差分析。计算误差的方式重投影误差，即为根据重建出来的参数，将三维空间中的棋盘格投影到图像平面上，计算投影之后的点与实际检测出来的角点之间的欧氏距离。

对于单个相机的情况，我们分别统计了对于每个相机，其在所有使用到的棋盘格照片的重投影误差，如图\ref{fig:cal-one}所示。从图中可以看出，对于单个相机的标定，其误差能够控制在 个像素范围内，表明对单个相机的参数标定基本准确。对于所有相机的外参的标定，我们使用同一个时刻的静止的棋盘格，将其投影到各个相机视角下，计算其各自的重投影误差，如图\ref{fig:cal-all}所示。从图中可以看出，在使用该方法计算外参时，重投影误差也较低，说明我们的标定方法可靠，可以作为下一步计算的参数。

\subsection{三维重建}

\subsubsection{三角法}
% https://scm_mos.gitlab.io/2018/12/08/triangulate/
对于三维空间中的一点$\bfX$，其在世界坐标系中的表示为
\begin{equation}
    \bfX = [x,y,z,1]^T
\end{equation}
第$i$个相机的参数矩阵为
\begin{equation}
    P_i = K_i[R_i | t_i] = \left[ \begin{array}{c}
            P_{i1} \\ P_{i2} \\ P_{i3}
        \end{array}\right]
\end{equation}
点$X$在第$i$个相机中的投影的坐标为
\begin{equation}
    \bm{x_i} = (x_i, y_i, 1)^T
\end{equation}
根据投影方程，即有
\begin{equation}
    \bm{x_i} = P_i\bfX
\end{equation}
上式两边同时叉乘$\bm{x_i}$，即有
\begin{equation}
    \bm{x_i} \times (P_i\bfX) = 0
\end{equation}
展开即可得到：
\begin{align}
    x_i(P_{i3}\bm{X}) & - P_{i1}\bm{X} = 0   \\
    y_i(P_{i3}\bm{X}) & - P_{i2}\bm{X}= 0    \\
    x_i(P_{i2}\bm{X}) & - y_iP_{i1}\bm{X}= 0
\end{align}
第三个方程与前两个方程线性相关，因此该组方程实际只提供了两个自由度，即
\begin{align}
    \left[ \begin{array}{c}
            x_iP_{i3} - P_{i1} \\ y_iP_{i3} - P_{i2}
        \end{array}\right]\bm{X} = \bm{0}
\end{align}
因此每个相机上的一个观察点提供了两个约束，而该点的坐标有三个自由度，因此至少需要两个视角才能解出一个点的坐标。而我们的能用的视角个数大于两个，也就是说需要求解超定方程。即求解超静定的齐次线性方程
\begin{equation}
    AX = \bm{0}
\end{equation}
因此我们采用SVD分解的方法，计算$A$矩阵奇异值最小的对应的奇异向量，就是三维坐标的解。那么我们的问题即为假定未知的所有的关节的三维点的坐标为$S\in \mathbb{R}^{3\times N}$，$N$为关节点的数目，第$i$ 个相机的参数为$R_i,T_i,K_i$。那么该问题的方程可写为：

\unsure{}{这里需要补充一下SVD解方程的解法}

\begin{equation}
    \left[ \begin{array}{c}
            x_{n0}P_{03} - P_{01} \\
            y_{n0}P_{03} - P_{02} \\
            x_{n1}P_{13} - P_{11} \\
            y_{n1}P_{13} - P_{12} \\
            \vdots                \\
            x_{ni}P_{i3} - P_{i1} \\
            y_{ni}P_{i3} - P_{i2}
        \end{array}\right] \left[ \begin{array}{c}
            X_n \\
            Y_n \\
            Z_n \\
            1
        \end{array}\right]  = \bm{0}, n = 1,2,\ldots,N
\end{equation}
对于所有关节点，求解方程即可获得所有关节点的三维空间坐标。

为了对该方法进行量化，同样我们在Human3.6M数据集上进行测试，该数据集包含了四个相机的视角，数量小于LightStage数据集的相机数目，我们使用全部视角下的二维检测结果，以及给定的相机参数进行重建。通常对于三维关节点估计的评价指标是平均关节位置误差(Mean Per Joint Position Error，简称MPJPE)，即估计的关节坐标与真实的关节坐标之间的欧氏距离的平均值。此外，由于采集数据的运动捕捉系统本身也会带来一些噪声，因此除了平均关节位置误差外，研究中通常使用的指标还有正确关节点百分比(Percentage of Correct Key-points，简称PCK)，该指标描述的是估计的关节坐标与真实的关节坐标之间的欧式距离小于给定阈值的百分比。通常该阈值指定为150mm。
使用平均关节位置误差以及正确关节点百分比两个指标，将我们的算法在Human3.6M数据集上进行测试，可以得到在测试数据上的平均关节位置误差为45.9mm，正确关节点百分比为99.8\%，其各个关节的详细的平均位置误差如表\ref{tab:3derrorjoint}所示，各个关节的正确关节点百分比如表\ref{tab:3dpck}所示。从两个表中可以看出，对于大部分的检测结果，均在150mm的范围内，而少部分错误检测的结果会使得误差的均值和方差都增大。从表格中可以看出，越远离躯干的部位，其正确关节点百分比越低，通过对误差较大的情况进行可视化发现，错误的主要原因是在出现了自遮挡的时候，左手腕和右手腕互相检测错误，导致误差增大。因此我们需要想办法解决该问题。

\begin{table}[H]
    \centering
    \begin{tabular}{lllllll}
        \hline
                     & 左臀  & 左膝  & 左踝  & 右臀  & 右膝  & 右踝  \\
        \hline
        关节误差(mm) & 59±17 & 46±18 & 77±17 & 77±12 & 40±22 & 63±29 \\
                     & 左肩  & 左肘  & 左腕  & 右肩  & 右肘  & 右腕  \\
        关节误差(mm) & 29±20 & 35±15 & 25±14 & 36±22 & 33±14 & 31±62 \\
        \hline
    \end{tabular}
    \caption{三角法重建各关节误差（单位：mm）\label{tab:3derrorjoint}}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{lllllll}
        \hline
            & 左臀     & 左膝    & 左踝    & 右臀     & 右膝     & 右踝    \\
        \hline
        PCK & 100.00\% & 99.51\% & 99.76\% & 100.00\% & 99.34\%  & 99.86\% \\
            & 左肩     & 左肘    & 左腕    & 右肩     & 右肘     & 右腕    \\
        PCK & 100.00\% & 99.98\% & 99.93\% & 100.00\% & 100.00\% & 99.74\% \\
        \hline
    \end{tabular}
    \caption{三角法正确关节点百分比\label{tab:3dpck}}
\end{table}


\subsubsection{优化法}
由于在实际情况中，我们得到的二维关节点不一定在每个相机下都可见，因此我们需要通过一个权值来控制该关节点在一个相机视角下的可见性。同时，由于深度神经网络的输出带有不确定性，其对每个关节的检测结果均会有一个置信度的指标，置信度大即表示深度神经网络模型认为该点为对应关节的概率大，反之置信度小则表示该点是该关节的不确定性较大。那么我们在恢复人体的三维关节坐标时即可将该权重纳入考虑范围内，即更加相信那些置信度高的视角下的检测结果，通过这种方法来使我们的模型更加鲁棒。

由前文可知，相机投影模型为
\begin{equation}
    Z_i \bm{x_i} = K_i(R_i\bm{X} + T_i)
\end{equation}
投影坐标即为
\begin{equation}
    \bm{x_i} = Z_i^{-1}K_i(R_i\bfX + T_i)
\end{equation}
那么根据各个视角下的观测到的二维坐标，我们的目标函数可以写为
\begin{equation}
    \min \sum^I_{i=1} \sum_{n=1}^N w_{in}||x_{in} - \hat x_{in}||_2
\end{equation}
将投影坐标表达式代入，即得
\begin{equation}
    L_{repro} \sum^I_{i=1} \sum_{n=1}^N w_{in}||Z_i^{-1}K_i(R_iX_n + T_i) - \hat x_{in}||_2
\end{equation}
\newcommand{\mi}{第\(i\)个}
\newcommand{\mn}{第\(n\)个}
其中，$w_{in}$表示\mi 相机视角下，\mn 关节点的对应的深度神经网络检测的二维位置的置信度；$\hat x_{in}$ 表示\mi 相机视角下，\mn 关节点通过深度神经网络估计的在图像平面上的位置；$X_n$为\mn 关节的三维齐次坐标。

\textbf{骨长约束}：对于人体来说，我们知道人体的各个关节不应该是独立的点，而在我们之前的优化与求解的过程中，并没有考虑该依赖关系，那么为了引入该先验，我们可以简单的使用骨长来给之前的优化变量增加约束。我们从一个大型的人体数据集中可以统计得到人体的骨长的均值和方差，即我们假设，对于关节点\(i,j\)所在的骨架，其长度\(L_{ij}\)服从均值为\(L_{ij}\)，方差为\(\sigma_{ij}\)的正态分布，我们可以预先统计得到该正态分布的参数，在进行优化时将该项也作为最小化的项。我们可以计算对于输入的关节坐标\(\bm{X}\)，其似然概率为
\begin{equation}
    p  = \prod _ { ( a,b ) \in \varepsilon } N \left( \left\| \boldsymbol {X} _ { a } - \boldsymbol {X} _ { b } \right\| | L _ {ab} , \sigma _ {ab} \right)
\end{equation}
其中先验项表示关节\(a\)和关节\(b\)的结构依赖关系，这一项约束了两个关节点的骨架长度，其中，\(\left\| \boldsymbol {X} _ { a } - \boldsymbol {X} _ { b } \right\|\) 表示关节点\(\boldsymbol {X} _ { a }, \boldsymbol {X} _ { b } \)的欧几里得距离，\(\varepsilon\)表示人体的骨架结构中的边。在进行优化时一般的最大化似然函数\(p\)的方法是，先将状态空间离散化，成为一个三维空间的网格结构，接着使用最大积(max-product)算法\cite{max-product}。然而随着状态空间的维度的增加，最大积算法的计算复杂度增长得十分快，效率较低。因此我们没有采用对空间网格进行划分的办法，由于我们前一步已经通过三角法获得了关节的三维空间位置的值，我们直接将该值作为初值，最大化似然函数即可以转化为最小化似然函数的对数的负数，通过取对数能够将似然函数里的乘法转化为加法，将指数计算去掉，这样能够有效提高优化时的计算速度，因此关于骨架结构的损失函数即可以写为
\begin{equation}
    L_{s} = -\log p = \log (\sigma \sqrt{2\pi}) + \frac{(\left\| \boldsymbol {X} _ { a } - \boldsymbol {X} _ { b } \right\| - L_{ij})^2}{2\sigma^2}
\end{equation}

% \textbf{运动约束}：同样我们可以知道，人体的运动状态也是无法突变的，人的关节位置也是无法突变的，那么将其数学化表达，即是说我们希望相邻两帧的人的关节位置的差尽量小，通过这一项约束，我们可以限制前后帧之间的由于检测错误出现的突变，数学化表达式记为：
% \begin{equation}
%     L_{t} = 
% \end{equation}
\begin{table}[H]
    \centering
    \begin{tabular}{lllllll}
        \hline
                     & 左臀  & 左膝  & 左踝  & 右臀  & 右膝  & 右踝  \\
        \hline
        关节误差(mm) & 39±16 & 44±16 & 68±16 & 43±16 & 41±19 & 66±26 \\
                     & 左肩  & 左肘  & 左腕  & 右肩  & 右肘  & 右腕  \\
        关节误差(mm) & 28±17 & 33±13 & 22±12 & 30±15 & 33±14 & 24±56 \\
        \hline
    \end{tabular}
    \caption{优化法重建各关节误差（单位：mm）均值39.1,26.8\label{tab:3derroropt}}
\end{table}

\subsection{量化分析}
% 这里还需要写一下重投影之后的误差是多少
\unsure{}{把在CMU上测的拿来写一下}

\begin{table}[H]
    \centering
    \begin{tabular}{lllllll}
        \hline
                     & 左臀   & 左膝   & 左踝   & 右臀   & 右膝   & 右踝   \\
        \hline
        关节误差(mm) & 24, 48 & 37, 29 & 31, 85 & 27, 59 & 35, 35 & 33, 37 \\
                     & 左肩   & 左肘   & 左腕   & 右肩   & 右肘   & 右腕   \\
        关节误差(mm) & 14, 8  & 30, 12 & 38, 16 & 15, 7  & 25, 11 & 31, 15 \\
        \hline
    \end{tabular}
    \caption{CMU的结果（单位：mm）均值28.4, 38.7\label{tab:3derrorcmu}}
\end{table}
\subsection{模型应用}

由上述分析，我们知道该方法是可靠的，因此我们可以对其在我们的数据上进行应用。我们的数据采集了三个演员的不同动作，并分别对三段动作都进行了重建，在重建的时候，我们使用OpenPose对人体的脸部关键点与手部关键点也进行了重建，从可视化的结果来看，该重建是有效的。

由图中可以看出，我们的系统采集到的高清照片能够保留足够多的信息，使得能从中检测到相应的特征点，因此能够对人体的比较细小的关节点进行检测与重建，而这是传统的基于标记点的重建方法无法做到的。

\unsure{}{把在LightStage上的测的结果多贴一点图}
