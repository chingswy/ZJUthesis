\section{人体二维姿态估计问题的研究}
\subsection{问题描述}
人体二维人体姿态估计问题，即是说给定输入的图片或视频序列，进行处理得到相应的人体各个关节在图片上的位置。
\subsection{研究方法比较}
人体二维姿态估计目前有两个主流方案，第一种是自顶向下的方法，这种方法先检测图片中的人体，得到一个人体的检测框，然后去分别检测每一个人的人体区域中的姿态；另一种是自底向上的方法，首先检测出图片中的所有的人的肢体的关节节点，然后将关节节点进行拼接，得到人体的骨架。自顶向下的方法中，姿态检测的准确度会依赖于人体区域框的检测质量；而在自底向上的方法中，如果两个人离得较近，会出现拼接错误的情况；同时由于依赖的是关节之间的联系，所以对全局信息的获取会有不足。目前主流的开源人体二维检测方案主要有几种，罗列如下。
\begin{itemize}
    \item CPN 
    \item OpenPose
    \item AlphaPose
\end{itemize}
下面依次介绍这几种模型。
\subsubsection{OpenPose}
OpenPose是由CMU提出的多人二维关键点实时检测方案，该方案是基于自底向上的思想的。该方法使用了一种叫部件亲和场(Part Affinity Fields，简称PAF)的非参数表示方法，通过这种方法将检测出来的人体关节组合起来。部件亲和场的表示方法是指，对于人体上的骨架上的每一个像素，去回归这一段骨架的方向向量。该方法具有较高的精度以及较好的实时性。该方法可以同时对人体的身体部分、双脚、手部关节点、脸部关键点进行检测，输出结果较为丰富。
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figure/2dpose/openpose}
    \caption{\label{fig:2d-op} OpenPose流程图}
\end{figure}
该方法主要分为几个步骤，首先对于一张输入的图片，OpenPose将整张图片都输入给深度卷积神经网络，通过网络同时去回归人体的独立的关节点的位置，以及部件亲和场。通过对回归的结果进行组合将候选的关节进行组合，匹配属于同一个人的关节，最后就能得到整个人体的完整的身体姿态。

\subsubsection{AlphaPose}
AlphaPose是上海交通大学卢策吾教授团队开源的二维人体关键点检测方法，该方法使用的是自顶向下的方法，即首先检测人体所在的框的区域，再对框中的人体进行关键点检测。首先通过区域候选网络(Region Proposal Network)提出候选的人体区域，然后将所得到的所有的候选的人体区域框分为两支，一支通过单人姿态估计(Single Person Pose Estimation)算法，以及姿态非极大值抑制算法得到姿态，另一支直接通过单人姿态估计得到人体的姿态，最后将两支分路的结果进行整合，得到最终的人体姿态。 
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figure/2dpose/alphapose}
    \caption{\label{fig:2d-ap} AlpahPose流程图}
\end{figure}

\subsubsection{CPN}
级联金字塔网络(Cascaded Pyramid Network, 简称CPN)是有旷视科技提出的模型，该模型取得了COCO2017人体关键点挑战赛的冠军，该模型主要面向的问题是单张图片中的多人姿态估计问题。该模型属于自顶向下的方法，即首先生成人体的边界框，之后对单个人体的框进行关键点检测。级联金字塔网络包含了两个阶段，第一个阶段为全局网络(GlobalNet)，这部分用来从图像中提取特征，可以定位特征较为明显的关键点，例如手和脚，但是无法直接从图片中识别出被遮挡的关键点；第二个阶段为精炼网络(RefineNet)，这一阶段主要通过整合全局网络中识别得到的图片特征，来推断被遮挡住的关键点的位置。即是说理解可以看到的关键点所提供的上下文信息，完成所有关键点的检测任务。
\begin{figure}[H]
    \centering
    \includegraphics[width=.4\linewidth]{figure/2dpose/cpn}
    \caption{\label{fig:2d-cpn} CPN流程图}
\end{figure}
论文中的全局网络的骨架是深度残差网络\cite{resnet}，通过使用U形结构来整合不通尺度的空间分辨率的特征以及语义信息。精炼网络部分中，为了提高计算的效率，同时保持信息在传输过程中的完整性，精炼网络部分首先讲不同尺度的特征图进行堆叠，然后通过上采样和融合，将不同层次的信息进行融合。

\subsection{模型比较}
为了验证上述二维关节点检测模型在我们的实验环境下的准确度，我们需要对其进行定量的分析。由于我们的实验设备没有在人身上贴标签，因此无法得到准确的三维关键点以及二维关节点的坐标，因此我们选择了广泛使用的Human3.6M数据集。该数据集是最大的人体三维姿态数据集之一，包含了360万的图片，其中包括了11个演员以及15个日常动作，例如吃饭，走路等。该数据集的采集环境为室内环境，并且使用了总共4个相机来进行数据采集。该数据集通过在人体贴上标志物来获得人体的三维空间的关节位置，相对于从图片直接估计来说较为准确，因此我们通过该数据集来对我们的算法进行定量分析。

在这一部分中，我们使用Human3.6M数据集的图片，通过三种不同的人体二维关节点检测方法获得其关节位置，与其提供的二维关节点的位置进行比较，计算三种方法的误差。由于二维关节点的训练数据集中，关节的位置通常都是由人类标注者进行标注，而Human3.6M的关节点的位置是由其贴的标志的位置决定的，因此两者的关节定义有所不同，而在三种二维关节点检测方法中，其各自使用的训练数据集也有所区别，因此我们只选择了人的身体上的主要的几个点进行比较。

\begin{figure}[H]
    \centering
    \includegraphics[width=.4\linewidth]{figure/2dpose/compare}
    \caption{\label{fig:2d-compare} 三种二维人体关节点检测方法结果比较}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.4\linewidth]{figure/2dpose/compare}
    \caption{\label{fig:2d-loss} 各个关节的误差分布对比}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{lccc}
        \hline
         Name       &   OpenPose &     CPN &   AlphaPose \\
        \hline
         \text{误差均值（像素）}   &    9.62135 & 9.32769 &     8.78416 \\
         \text{误差标准差} &    6.35488 & 7.85625 &     4.63783 \\
        \hline
    \end{tabular}
    \label{tab:plan}%
    \caption{三种二维检测人体方法的误差}
\end{table}


\subsection{应用}
基于以上比较，我们发现\comment{模型}的精度较高，因此我们选择使用该模型在我们的模型上应用。部分图片的二维人体关节点检测结果如图所示。从二维关节点检测结果可以看出，目前的二维人体关节点模型可以在我们的数据上取得较好的结果。基于这一部分的结果，我们才能对人体的三维关节点进行重建。

